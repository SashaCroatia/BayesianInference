---
title: "MCMC"
author: "Alexander Berliner"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

## (i) Simulating Data from a Logistic Regression Model with Synthetic Predictors

Logistic regression is a binary classifier. We want to find the probability that the observation $P(y = 1 \mid \mathbf{x})$ is a member of a class.

Along with the training set $\mathbf{X}$, we have a vector $\boldsymbol{\beta}$ of weights for each feature, including the intercept. The resulting evidence for the class is given by:

$$
z = \mathbf{X} \boldsymbol{\beta}
$$

To convert $z$ into a probability, we pass it through the sigmoid (logistic) function:

$$
\sigma(z) = \frac{1}{1 + e^{-z}}
$$

**References**:

1.  <https://web.stanford.edu/~jurafsky/slp3/5.pdf>

**Setup:**

```{r}
#To be set by user:
n = 2000 #number of observations (set it higher for consistency)
beta <- c(1, 2, 3)#, 4, 5, 6)  # True coefficients (bias, and predictors) px1

#Synthetic predictors
p = length(beta)-1 #number of predictors
M = p+1 #number of predictors plus intercept
library(MASS)
X <- cbind(1, matrix(mvrnorm(n, mu = rep(0, p), Sigma = 1*diag(p)), n, p))  # Design matrix with intercept (bias). nxp

#Response
z <- X %*% beta  # Linear predictor. %*% = matrix mult. nx1 dim
sig <- 1/(1+exp(-z)) #sigmoid (inv-logit) function, find probability in [0,1], predicted y
y = rbinom(n=n, size=1, prob=sig) #size=num trials=1 -> bernoulli response var
```

## (ii) Basic MCMC.

As our goal is to compute the probability of the model given the data, we use Markov Chain Monte Carlo (MCMC) as our simulation (stochastic) method to obtain random samples of $\beta$. [1]

Some notes:

-   The Bayesian treatment views $\beta$ as a random variable with a prior distribution. In this example, $y\vert\beta\sim F_y$ with unknown parameter coefficients $\beta\sim F_\beta$. If there were external parameters influencing the coefficients, than those parameters would be the hyperparamters. This is inline with the practice of **Bayesian hierarchical modeling**. [1]

-   Our goal is to find the distribution $p(\beta\vert y, X)$. Bayes' rule for the posterior over the parameters is:\
    $$
    p(\beta\vert y, X) = \frac{p(y\vert X,\beta)p(\beta)}{\int p(y\vert X,\beta)p(\beta)d\beta}
    $$ where $p(y\vert X,\beta)$ is the likelihood, $p(\beta)$ is the prior, and the denominator is the marginal likelihood. As the integral may not be analytically solvable we resort to MCMC. [1]

-   **Importance sampling**: used for computing the expectation $E[\beta\vert y, X]$ by drawing from an approximation of the target distribution $p(\beta\vert y,X)$. Let $g(\beta)$ be the pdf of our sampling distribution (ie proposal distribution in MCMC). Then\
    $$
    E[\beta\vert y, X] = \frac{\int\beta\cdot p(y\vert X,\beta)p(\beta)d\beta}{\int p(y\vert X,\beta)p(\beta)d\beta} = 
    \frac{\int [\beta\cdot p(y\vert X,\beta)p(\beta)g(\beta)]/g(\beta) d\beta}{\int [p(y\vert X,\beta)p(\beta)g(\beta)]/g(\beta)d\beta}
    $$ can be estimated using $S$ draws $\beta^1,\ldots,\beta^2$ from $g(\beta)$ by\
    $$
    \frac{\frac{1}{S}\sum_{s=1}^S\beta^sw(\beta^s)}{\frac{1}{S}\sum_{s=1}^Sw(\beta^s)}
    $$\
    $$
    w(\beta^s) = \frac{p(y\vert X,\beta^s)p(\beta^s)}{g(\beta^s)}
    $$\
    are the importance ratios (weights). [1]

-   **Markov chain**: sequential sampling, where the last value drawn depends on the previously sampled value; $\beta^{i}$ depends on $\beta^{i-1}$. Choose $\beta^i$ from the transition distribution $T_i(\beta^i\vert\beta^{i-1})$; $i$ is iteration number. [1]

In MCMC for a sufficiently large $i$, we want the realization $\beta^i$ from the Markov Chain to converge to the marginal distribution $F_\beta$.

### Metropolis algorithm [1] 

0.  State the initial values: $N$ iterations, $M$ dimensions, and a $N$x$M$ matrix $b$ where the first row is our initial guess $\beta^0 = [\beta_1^0,\ldots,\beta_M^0]$, and the subsequent rows is the sequence of the Markov chain of samples.

<!-- -->

1.  At iteration $i$, propose a new sample $\beta_{prop}$ from a symmetric proposal distribution $J_i(\beta^*\vert\beta^{i-1})=J_i(\beta^{i-1}\vert\beta^*)$ [1]. The choice of the proposal distribution determines if the chain is irreducible and aperiodic, two sufficient conditions for convergence of Metropolis chains [2, 185].

2.  Compute the transition probability $P(\beta^*) = p(y\vert X, \beta^*)p(\beta^*)$ where $p(y\vert \cdot)$ is the likelihood and $p(\beta^*)$ is the prior.

3.  Compute the acceptance ratio at iteration $i$:\
    $$
    r = \frac{P(\beta^*)}{P(\beta^{i-1})} = \frac{p(y\vert X,\beta^*)p(\beta^*)}{p(y\vert X,\beta^{i-1})p(\beta^{i-1})}
    $$

4.  Accept or reject the proposal $\beta^*$:

    $$
    \beta_i = 
    \begin{cases}
    \beta^* & \text{with probability }\min(r,1)\\
    \beta^{-i-1} & \text{else}
    \end{cases}
    $$

**References:**

1.  BDA3 Ch. 10,11

2.  Givens et al. *Computational Statistics*

**Define initial functions:**

```{r}
#Proposal distro
proposal <- function(mu, lambda, sigma) {
  # Draw a single sample from multivariate normal
  distro <- mvrnorm(1, mu = mu, Sigma = lambda*sigma)
  return(distro)
}

# Log-likelihood function for logistic regression
logistic_ll <- function(beta, X, y) {
  z <- X %*% beta
  p <- 1 / (1 + exp(-z))
  loglike <- sum(log(p[y==1]))+sum(log((1-p)[y==0]))
  return(loglike)
}

# Log-prior of parameter that comes from proposal distro
library(mvtnorm)
log_prior <- function(distro, mu, sigma) {
  # Compute the density at 'distro' under the MVN used in proposal()
  prob <- dmvnorm(distro, mean = mu, sigma = sigma)
  log_prob = log(prob)
  return(log_prob)
}
```

**Metropolis implementation:**

```{r}
metropolis <- function(X, y, M, N = 20000, a_target = 0.234, b1 = rep(0, M), batch = TRUE, batch_schedule = seq(50, N, by = 50)) {
  #0) Initial values
  n_accept <- 0 #number of acceptances
  b <- matrix(0, nrow = N, ncol = M)
  b[1,] <- b1 #rep(0, M)
  
  #Keep history of proposals
  P_list <- rep(NA, N - 1)
  P_list[1] <- logistic_ll(b[1,], X, y)
  
  #Adaptation parameters
  batch_index <- 1
  Tb <- 0 #start of batch
  mu <- rep(0, M)
  Sigma <- diag(M)
  lambda <- (2.38**2)/M
  gam <- 1
  
  for (i in 2:N) {
    #1) Propose new position beta[i-1] -> beta[i]' from proposal distro
    b_prop <- proposal(mu, lambda, Sigma)
    
    #2) Compute transition probability
    P_list[i] <- logistic_ll(b_prop, X, y) + log_prior(b_prop, rep(0, M), diag(M))  #P(beta*)
    
    #3) Acceptance ratio
    R <- exp(P_list[i] - P_list[i-1])
    alpha <- min(R, 1)
    
    #4) Generate a random number u_i from [0,1]. Accept or reject proposal
    u <- runif(1)  # u_i
    if (u <= alpha) {
        b[i,] <- b_prop  # Accept y as next state
        n_accept = n_accept + 1
    } else {
        b[i,] <- b[i-1,]  # Stay at previous state of Markov chain
        P_list[i] = P_list[i-1]
    }
    
    #5) Adaptive step
    if (batch == TRUE) {
      if (batch_index <= length(batch_schedule) && i == batch_schedule[batch_index]) {
        #Batch update
        Tb1 = i #T_{b+1}
        b_batch = b[(Tb + 1):Tb1,]
        n_batch = nrow(b_batch)
        
        #Covar update
        cov_sum = matrix(0, M, M)
        for (j in 1:n_batch) {
          diff = matrix(b_batch[j,] - mu, ncol=1)
          cov_sum = cov_sum + (diff%*%t(diff) - Sigma)
        }
        Sigma <- Sigma + cov_sum/n_batch + 1e-5*diag(M)
        
        #Mean update
        mean_diff = colMeans(b_batch) - mu
        mu = mu + mean_diff
        
        #Parameter update
        Tb = Tb1
        batch_index = batch_index + 1
        lambda = exp( log(lambda) + (R-a_target)/n_batch )
      }
    } else { #Batch == FALSE
      gam = 1/i
      sigma = sigma + gam*( (b[i,]-mu)%*%t(b[i,]-mu) - sigma )
      mu = mu + gam*( b[i,]-mu )
      lambda = exp( log(lambda) + gam*(R-a_target) )
    }
  }

  n <- as.integer(0.9 * N)
  C <- b[(N - n + 1):N,] #discard first 10% of samples
  
  cat("Acceptance rate:", n_accept/(N-1), "\n")
  return(C)
}
```

```{r}
C = metropolis(X, y, M)
```

$\beta$ distribution estimate:

```{r}
c = C[,1]
# Plot of density function
library(ggplot2)
nbins <- ceiling( (2*n)**(1/3) ) #Terrell-Scott rule for min num bins
ggplot() +
  geom_histogram(aes(x = c, y = ..density..), bins = nbins, fill = "orange", color = "black", alpha = 0.6) +
  geom_density(aes(x = c), color = "blue", linewidth = 1) +
  labs(x = "l", y = "Density", title = "MCMC Approximation of the Posterior") +
  xlim(min(c), max(c)) +
  theme_minimal()
```

Traceplots

```{r}
library(coda)
mcmc_obj <- as.mcmc(C)
traceplot(mcmc_obj)
```

Autocorrelation plots

```{r}
autocorr.plot(mcmc_obj)
```
